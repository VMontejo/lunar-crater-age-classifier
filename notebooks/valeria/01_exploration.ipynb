{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "822d8959",
   "metadata": {},
   "source": [
    "# üöÄ Lunar Crater Age Classification: Data Exploration\n",
    "**Objective**: To systematically explore and characterize the dataset, informing preprocessing strategies and model architecture decisions for classifying craters as **\"Fresh\"**, **\"Old\"**, or **\"None\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6077189",
   "metadata": {},
   "source": [
    "## üìÅ 1. Dataset Structure & Inventory\n",
    "*Goal: Understand the organization and volume of our data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd752d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from  PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a19e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../../raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a11ddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure:\n",
      "\n",
      "TRAIN:\n",
      " ejecta: 358 images\n",
      " oldcrater: 594 images\n",
      " none: 2656 images\n",
      "\n",
      "VAL:\n",
      " ejecta: 55 images\n",
      " oldcrater: 118 images\n",
      " none: 440 images\n",
      "\n",
      "TEST:\n",
      " ejecta: 89 images\n",
      " oldcrater: 157 images\n",
      " none: 533 images\n"
     ]
    }
   ],
   "source": [
    "#Exploring the structure\n",
    "print(\"Dataset structure:\")\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    split_path = data_path / split\n",
    "    for class_name in [\"ejecta\", \"oldcrater\", \"none\"]:\n",
    "        class_path = split_path / class_name\n",
    "        num_images = len(list(class_path.glob(\"*.jpg\")))\n",
    "        print(f\" {class_name}: {num_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a9914",
   "metadata": {},
   "source": [
    "## üëÅÔ∏è 2. Visual Sample Gallery\n",
    "*Goal: Build an intuitive, visual understanding of each class.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29dd0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data frame for visualization\n",
    "data = []\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    count = len(list((data_path / split / class_name).glob(\"*.jpg\")))\n",
    "    data.append({\"split\": split, \"class\": class_name, \"count\": count})\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf1ad62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='class'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.pivot(index=\"class\", columns=\"split\", values= \"count\").plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a541b",
   "metadata": {},
   "source": [
    "## üìê 3. Technical Image Analysis\n",
    "*Goal: Determine the technical specifications and necessary transformations.*\n",
    "**Key Questions:**\n",
    "- What are the image dimensions (height, width)?\n",
    "- What is the color mode (RGB, Grayscale)?\n",
    "- What is the distribution of pixel intensities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc344ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image dimensions\n",
    "sizes = []\n",
    "for class_name in [\"ejecta\", \"oldcrater\", \"none\"]:\n",
    "    class_path = data_path / \"train\" / class_name\n",
    "    for img_path in list(class_path.glob(\"*.jpg\"))[:3]:\n",
    "        with Image.open(img_path)as img:\n",
    "            width, height = img.size\n",
    "            sizes.append({\"class\": class_name,\n",
    "                          \"width\": width,\n",
    "                          \"height\": height,\n",
    "                          \"aspect_ratio\": width/height,\n",
    "                          \"filename\": img_path.name})\n",
    "df_sizes = pd.DataFrame(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e21f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ejecta</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M159705621LC_pyr-0144.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ejecta</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M1116046457RC_pyr-0593.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ejecta</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M1178246048RC_pyr-0694.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldcrater</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M1178352512RC_pyr-0240.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oldcrater</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M1157756910LC_pyr-1398.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oldcrater</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M1095437275RC_pyr-0618.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M119217559LC_pyr-0815.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M1106595881LC_pyr-2050.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>none</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M1178352512RC_pyr-0268.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  width  height  aspect_ratio                    filename\n",
       "0     ejecta    227     227           1.0   M159705621LC_pyr-0144.jpg\n",
       "1     ejecta    227     227           1.0  M1116046457RC_pyr-0593.jpg\n",
       "2     ejecta    227     227           1.0  M1178246048RC_pyr-0694.jpg\n",
       "3  oldcrater    227     227           1.0  M1178352512RC_pyr-0240.jpg\n",
       "4  oldcrater    227     227           1.0  M1157756910LC_pyr-1398.jpg\n",
       "5  oldcrater    227     227           1.0  M1095437275RC_pyr-0618.jpg\n",
       "6       none    227     227           1.0   M119217559LC_pyr-0815.jpg\n",
       "7       none    227     227           1.0  M1106595881LC_pyr-2050.jpg\n",
       "8       none    227     227           1.0  M1178352512RC_pyr-0268.jpg"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d0d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color channel investigation\n",
    "pixel_stats = []\n",
    "for class_name in [\"ejecta\", \"oldcrater\", \"none\"]:\n",
    "    class_path = data_path / \"train\" / class_name\n",
    "    for img_path in list(class_path.glob(\"*.jpg\"))[:2]:\n",
    "        with Image.open(img_path) as img:\n",
    "            #Convert to numpy array for analysis\n",
    "            img_array = np.array(img)\n",
    "            pixel_stats.append({\"class\": class_name,\n",
    "                                \"mode\": img.mode,\n",
    "                                \"shape\": img_array.shape,\n",
    "                                \"min\": img_array.min(),\n",
    "                                \"max\": img_array.max(),\n",
    "                                \"mean\": img_array.mean().round(2),\n",
    "                                \"std\": img_array.std().round(2),\n",
    "                                \"dtype\": img_array.dtype})\n",
    "\n",
    "df_pixels = pd.DataFrame(pixel_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75e2e694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>mode</th>\n",
       "      <th>shape</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ejecta</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(227, 227, 3)</td>\n",
       "      <td>25</td>\n",
       "      <td>255</td>\n",
       "      <td>154.81</td>\n",
       "      <td>28.62</td>\n",
       "      <td>uint8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ejecta</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(227, 227, 3)</td>\n",
       "      <td>17</td>\n",
       "      <td>196</td>\n",
       "      <td>64.41</td>\n",
       "      <td>20.90</td>\n",
       "      <td>uint8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oldcrater</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(227, 227, 3)</td>\n",
       "      <td>97</td>\n",
       "      <td>253</td>\n",
       "      <td>127.18</td>\n",
       "      <td>13.95</td>\n",
       "      <td>uint8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldcrater</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(227, 227, 3)</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>99.03</td>\n",
       "      <td>20.96</td>\n",
       "      <td>uint8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(227, 227, 3)</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>85.61</td>\n",
       "      <td>18.53</td>\n",
       "      <td>uint8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "      <td>RGB</td>\n",
       "      <td>(227, 227, 3)</td>\n",
       "      <td>18</td>\n",
       "      <td>215</td>\n",
       "      <td>87.88</td>\n",
       "      <td>16.72</td>\n",
       "      <td>uint8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class mode          shape  min  max    mean    std  dtype\n",
       "0     ejecta  RGB  (227, 227, 3)   25  255  154.81  28.62  uint8\n",
       "1     ejecta  RGB  (227, 227, 3)   17  196   64.41  20.90  uint8\n",
       "2  oldcrater  RGB  (227, 227, 3)   97  253  127.18  13.95  uint8\n",
       "3  oldcrater  RGB  (227, 227, 3)    0  253   99.03  20.96  uint8\n",
       "4       none  RGB  (227, 227, 3)    0  186   85.61  18.53  uint8\n",
       "5       none  RGB  (227, 227, 3)   18  215   87.88  16.72  uint8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87e66b",
   "metadata": {},
   "source": [
    "**Image Dimensions**: All images are `227√ó227` pixels (confirmed via dataset documentation and sample verification).\n",
    "\n",
    "**Implications for Preprocessing**:\n",
    "- ‚úÖ **No resizing required** - images are already uniform\n",
    "- ‚úÖ **Square aspect ratio** (1:1) - no distortion needed\n",
    "- ‚úÖ **Compatible** with common CNN architectures\n",
    "\n",
    "**Preprocessing Decision**: We will use the native `227√ó227` size for our models.\n",
    "\n",
    "**‚úÖ Color and Pixel analysis COMPLETE:**\n",
    "- **Color Mode**: All images are `RGB` (3 channels)\n",
    "- **Value Range**: `[0, 255]` (uint8) ‚Üí needs normalization`[0,1]` \n",
    "- **Brightness Variability**: \"Ejecta\" class shows high variance (64-154 mean), suggesting illumination differences\n",
    "\n",
    "**Preprocessing Decisions:**\n",
    "1. `ToTensor()` for automatic `[0,255]` ‚Üí `[0,1]` conversion\n",
    "2. **Normalization needed** - Will calculate exact mean/std from full dataset\n",
    "3. **Color preserved** - Use all 3 RGB channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c0aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean and std for normalization\n",
    "def calculate_channel_stats(sample_size=100):\n",
    "    pixel_sum = np.zeros(3)\n",
    "    pixel_sq_sum = np.zeros(3)\n",
    "    count = 0\n",
    "\n",
    "    for class_name in [\"ejecta\", \"oldcrater\", \"none\"]:\n",
    "        class_path = data_path / \"train\" / class_name\n",
    "        for img_path in list(class_path.glob(\"*.jpg\"))[:sample_size//3]:\n",
    "            with Image.open(img_path) as img:\n",
    "                img_array = np.array(img) / 255.0     #Normalize to [0,1]\n",
    "                pixel_sum += img_array.mean(axis=(0,1))\n",
    "                pixel_sq_sum += (img_array**2).mean(axis=(0,1))\n",
    "                count += 1\n",
    "\n",
    "    mean = pixel_sum / count\n",
    "    std = np.sqrt(pixel_sq_sum / count - mean**2)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86206f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per channel (R, G, B): [0.3306 0.3306 0.3306]\n",
      "Std per channel (R, G, B): [0.1618 0.1618 0.1618]\n"
     ]
    }
   ],
   "source": [
    "mean, std = calculate_channel_stats(150)\n",
    "print(f\"Mean per channel (R, G, B): {mean.round(4)}\")\n",
    "print(f\"Std per channel (R, G, B): {std.round(4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "309e2e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For DataLoader\n",
    "normalization_stats = {\"mean\": list(mean.round(4)),\n",
    "                       \"std\": list(std.round(4))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e27d8",
   "metadata": {},
   "source": [
    "**Calculated from 150-image sample (50 per class):**\n",
    "- **Mean (R, G, B)**: `[0.3306, 0.3306, 0.3306]` -> low mean: the surface is dark gray on average\n",
    "- **Standard Deviation (R, G, B)**: `[0.1618, 0.1618, 0.1618]` -> low std: Relatively low contrast accross the dataset\n",
    "- **Key Insight**: Identical values across RGB channels ‚Üí lunar images are effectively **grayscale**. This suggests we could potentially convert to single-channel later for efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3716fbd3",
   "metadata": {},
   "source": [
    "# Data preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61fb9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and setup\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import List, Tuple, Dict\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d08a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants for exploration\n",
    "IMAGE_SIZE = (227, 227)\n",
    "NORM_MEAN = [0.3306, 0.3306, 0.3306]\n",
    "NORM_STD = [0.1618, 0.1618, 0.1618]\n",
    "CLASS_NAMES = [\"ejecta\", \"oldcrater\", \"none\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c934a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Pre processing functions---\n",
    "def load_and_validate_image(path: Path) -> np.array:\n",
    "    \"\"\"\n",
    "    Load image and ensure its 227 x 227 RGB\n",
    "    Returns: Numpy array shape (227,227,3)\n",
    "\n",
    "    Args:\n",
    "        Path to the .jpg file\n",
    "\n",
    "    Returns:\n",
    "        NumPy array of shape (227, 227, 3) with dtype uint8 (0-255)\n",
    "    \"\"\"\n",
    "    with Image.open(path) as img:\n",
    "        #Convert to RGB if needed\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "        #Check size\n",
    "        if img.size != IMAGE_SIZE:\n",
    "            raise ValueError(f\"Image {path.name} is {img.size}, expected {IMAGE_SIZE}\")\n",
    "\n",
    "        return np.array(img) #Shape (227, 227, 3), dtype: uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ddd52af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227, 227, 3),\n",
       " dtype('uint8'),\n",
       " np.uint8(17),\n",
       " np.uint8(196),\n",
       " np.float64(64.41328184129326))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejecta_path = data_path / \"train\" / \"ejecta\"\n",
    "test_image_path = list(ejecta_path.glob(\"*.jpg\"))[1]\n",
    "\n",
    "#Call Function\n",
    "image_array = load_and_validate_image(test_image_path)\n",
    "#Check results:\n",
    "image_array.shape, image_array.dtype, image_array.min(), image_array.max(), image_array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1115af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image_array: np.ndarray) -> np.array:\n",
    "    \"\"\"\n",
    "    Applies z-score normalization to lunar crater images\n",
    "    Converts [0, 255] range -> normalized range ~[-2, +2]\n",
    "    Centers data around 0 (mean = 0, std = 1)\n",
    "    Helps model to focus on crater features, not brightness\n",
    "\n",
    "    Formula:\n",
    "        1. Scale: img_float = img_array / 255.0\n",
    "        2. Normalize: img_normalized = (img_float - 0.3306) / 0.1618\n",
    "\n",
    "    Args:\n",
    "        img_array: NumPy array from load_and_validate_image()\n",
    "\n",
    "    Returns:\n",
    "        Normalized array, shape (227, 227, 3), dtype:float32\n",
    "    \"\"\"\n",
    "\n",
    "    #Convert to float32 and scale to [0, 1]\n",
    "    img_float = image_array.astype(np.float32) / 255.0\n",
    "\n",
    "     #Z-score normalization using our calculated statistics\n",
    "    NORM_MEAN = 0.3306   # #Averge moon brightness (dark grey)\n",
    "    NORM_STD = 0.1618    # Standard deviation of moon brightness\n",
    "\n",
    "    return (img_float - NORM_MEAN) / NORM_STD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d54384a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227, 227, 3), dtype('float32'), np.float32(-1.631232), np.float32(2.7072155))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call normalized function\n",
    "normalized_array = normalize_image(image_array)\n",
    "normalized_array.shape, normalized_array.dtype, normalized_array.min(), normalized_array.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4673d92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(-0.4820697)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d7f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_single_image(image_path: Path) -> np.array:\n",
    "    \"\"\"\n",
    "    Complete preprocessing for one lunar image\n",
    "    Combines loading, validation and normalization in one call\n",
    "\n",
    "    Pipeline:\n",
    "        1.load_and_validate_image()-\n",
    "        2.normalize_image() - applies z-score normalization\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to .jpg file\n",
    "\n",
    "    Returns:\n",
    "        Preprocessed image array, ready for models\n",
    "        Shape: (227, 227, 3), dtype: float32\n",
    "        Values normalized\n",
    "    \"\"\"\n",
    "\n",
    "    #Step 1: Load and validate\n",
    "    raw_image = load_and_validate_image(image_path)\n",
    "\n",
    "    #Step 2: Normalize\n",
    "    process_image = normalize_image(raw_image)\n",
    "\n",
    "    return process_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "241eb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_subset(\n",
    "    data_dir: Path,\n",
    "    samples_per_class: int =358,     #Match the smallest class(ejecta)\n",
    "    seed: int = 42\n",
    ")->List[Tuple[Path, int]]:\n",
    "    \"\"\"\n",
    "    Create a balance data set by downsampling the majority class.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to folder with class subfolders (ejecta/train/none)\n",
    "        samples_per_class: Number of samples per class (default to ejecta count)\n",
    "        seed: Random seed for reproductibility\n",
    "\n",
    "    Returns:\n",
    "        List of(image_path, class_index) tuples\n",
    "        class_index: 0=ejecta, 1=oldcrater, 2=none\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    class_names = [\"ejecta\", \"oldcrater\", \"none\"]\n",
    "    balance_samples = []\n",
    "\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_path = data_dir / class_name\n",
    "        all_files = list(class_path.glob(\"*.jpg\"))\n",
    "\n",
    "        if not all_files:\n",
    "            raise FileNotFoundError(f\"No images found in {class_path}\")\n",
    "\n",
    "        if class_name == \"none\":\n",
    "            #Downsample majority class\n",
    "            selected = random.sample(all_files, samples_per_class)\n",
    "        else:\n",
    "            selected = all_files[:min(samples_per_class, len(all_files))]\n",
    "\n",
    "        balance_samples.extend([(img_path, class_idx) for img_path in selected])\n",
    "\n",
    "    print(f\"‚úÖBalanced subset: {samples_per_class} samples per class\")\n",
    "    print(f\"Total: {len(balance_samples)} images\")\n",
    "    print(f\"Classes: {class_names}\")\n",
    "\n",
    "    return balance_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e7a6ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING: create_balanced_subset()\n",
      "==================================================\n",
      "‚úÖBalanced subset: 5 samples per class\n",
      "Total: 15 images\n",
      "Classes: ['ejecta', 'oldcrater', 'none']\n",
      "\n",
      "‚úÖ Class distribution: {0: 5, 1: 5, 2: 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING: create_balanced_subset()\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test with small number\n",
    "train_dir = data_path / \"train\"\n",
    "test_samples = create_balanced_subset(train_dir, samples_per_class=5)\n",
    "\n",
    "# Verify counts\n",
    "from collections import Counter\n",
    "class_counts = Counter([cls for _, cls in test_samples])\n",
    "print(f\"\\n‚úÖ Class distribution: {dict(class_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41307c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(\n",
    "    image_paths: List[Path],\n",
    "    output_dtype: type = np.float32\n",
    ")->np.array:\n",
    "    \"\"\"\n",
    "    Process multiple images efectively in batch\n",
    "\n",
    "    Args:\n",
    "        image_paths:List of paths to .jpg files\n",
    "        output_dtype: Output data type (default: float32)\n",
    "\n",
    "    Returns:\n",
    "        Batch array shape: (batch_size, 227, 227 3)\n",
    "        batch_size = len(image_paths)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "    from typing import List\n",
    "\n",
    "    batch_size = len(image_paths)\n",
    "    batch_array = np.zeros((batch_size, 227, 227, 3), dtype=output_dtype)\n",
    "\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        #Use our single_image function\n",
    "        processed = preprocess_single_image(img_path)\n",
    "        batch_array[i] = processed\n",
    "\n",
    "    return batch_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c8d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array_dataloader(\n",
    "    samples: List[Tuple[Path, int]],\n",
    "    batch_size: int = 32,\n",
    "    shuffle: bool = True,\n",
    "    seed: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a DataLoader that yields batches (more memory efficient)\n",
    "\n",
    "    Args:\n",
    "        samples: From create_balanced_subset() - list of (path, label)\n",
    "        batch_size: Images per batch\n",
    "        shuffle: Whether to shuffle data\n",
    "        seed: Random seed\n",
    "\n",
    "    Yields:\n",
    "        (batch_images, batch_labels) per iteration\n",
    "        - batch_images: shape (batch_size, 227, 227, 3), float32\n",
    "        - batch_labels: shape (batch_size,), int32\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import numpy as np\n",
    "    from typing import List, Tuple\n",
    "    from pathlib import Path\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(samples)\n",
    "\n",
    "    # Separate paths and labels\n",
    "    image_paths = [item[0] for item in samples]\n",
    "    labels = np.array([item[1] for item in samples], dtype=np.int32)\n",
    "\n",
    "    n_samples = len(samples)\n",
    "\n",
    "    # Yield batches\n",
    "    for start_idx in range(0, n_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, n_samples)\n",
    "\n",
    "        batch_paths = image_paths[start_idx:end_idx]\n",
    "        batch_labels = labels[start_idx:end_idx]\n",
    "\n",
    "        # Process this batch\n",
    "        batch_images = preprocess_batch(batch_paths)\n",
    "\n",
    "        yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "544f962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weighted_sampler(\n",
    "    samples: List[Tuple[Path, int]],\n",
    "    seed: int = 42\n",
    ")->List[Tuple[Path, int]]:\n",
    "    \"\"\"\n",
    "    Creates a weighted dataset to handle class imbalance.\n",
    "    Oversamples minority classes by duplicating samples based on class weights.\n",
    "    Returns a resampled list with balanced class distribution\n",
    "\n",
    "    Args:\n",
    "        samples: List of (image_path, class_label) tuples\n",
    "        seed: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    #Extract labels from samples\n",
    "    labels = [label for _, label in samples]\n",
    "\n",
    "    #Count samples per class\n",
    "    class_counts = Counter(labels)\n",
    "    class_names = [\"ejecta\", \"oldcrater\", \"none\"]\n",
    "\n",
    "    print(f\"Original class distribution:\")\n",
    "    for class_idx in sorted(class_counts.keys()):\n",
    "        class_name = class_names[class_idx]\n",
    "        count = class_counts[class_idx]\n",
    "        print(f\"{class_name}: {count} samples\")\n",
    "\n",
    "    #Calculate target number of samples per class (largest class)\n",
    "    max_samples = max(class_counts.values())\n",
    "\n",
    "    #Calculate weights: target / current count\n",
    "    weights = {}\n",
    "    resampled_samples = []\n",
    "\n",
    "    for class_idx in sorted(class_counts.keys()):\n",
    "        class_name = class_names[class_idx]\n",
    "        class_samples = [s for s in samples if s[1] == class_idx]\n",
    "\n",
    "        #weigth how many times we need to replicate\n",
    "        weight = max_samples / len(class_samples)\n",
    "\n",
    "        #determine ho many samples to add\n",
    "        num_needed = max_samples - len(class_samples)\n",
    "\n",
    "        if num_needed > 0:\n",
    "            #Randomly select samples ro duplicate\n",
    "            additional_samples = random.choices(class_samples, k = num_needed)\n",
    "\n",
    "            #Combine original + additional samples\n",
    "            resampled_class = class_samples + additional_samples\n",
    "        else:\n",
    "            #If already has max_samples, just use existing ones\n",
    "            resampled_class = class_samples\n",
    "\n",
    "        weights[class_idx] = weight\n",
    "        resampled_samples.extend(resampled_class)\n",
    "\n",
    "    #Shiffle the resampled dataset\n",
    "    random.shuffle(resampled_samples)\n",
    "\n",
    "    #Count final distribution\n",
    "    final_counts = Counter([label for _, label in resampled_samples])\n",
    "    print(f\"After weighted resampling\")\n",
    "    for class_idx in sorted(final_counts.keys()):\n",
    "        class_name = class_names[class_idx]\n",
    "        count = final_counts[class_idx]\n",
    "        weight = weights.get(class_idx, 1.0)\n",
    "        print(f\"{class_name}: {count} samples (weight: {weight:.2f})\")\n",
    "\n",
    "    return resampled_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60b063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Counter({2: 10, 1: 5, 0: 3})\n",
      "\n",
      "After weighted sampling:\n",
      "Original class distribution:\n",
      "ejecta: 3 samples\n",
      "oldcrater: 5 samples\n",
      "none: 10 samples\n",
      "After weighted resampling\n",
      "ejecta: 10 samples (weight: 3.33)\n",
      "oldcrater: 10 samples (weight: 2.00)\n",
      "none: 10 samples (weight: 1.00)\n",
      "Counter({1: 10, 2: 10, 0: 10})\n",
      "\n",
      "All classes should have 10 samples (largest class)\n",
      "Total samples went from 18 to 30\n"
     ]
    }
   ],
   "source": [
    "# Quick test in Python interpreter\n",
    "from collections import Counter\n",
    "\n",
    "# Create test data\n",
    "test_samples = []\n",
    "for i in range(3):  # ejecta\n",
    "    test_samples.append((Path(f\"ejecta_{i}.jpg\"), 0))\n",
    "for i in range(5):  # oldcrater\n",
    "    test_samples.append((Path(f\"oldcrater_{i}.jpg\"), 1))\n",
    "for i in range(10):  # none\n",
    "    test_samples.append((Path(f\"none_{i}.jpg\"), 2))\n",
    "\n",
    "print(\"Before:\")\n",
    "labels_before = [label for _, label in test_samples]\n",
    "print(Counter(labels_before))\n",
    "\n",
    "print(\"\\nAfter weighted sampling:\")\n",
    "resampled = create_weighted_sampler(test_samples, seed=42)\n",
    "labels_after = [label for _, label in resampled]\n",
    "print(Counter(labels_after))\n",
    "\n",
    "print(f\"\\nAll classes should have 10 samples (largest class)\")\n",
    "print(f\"Total samples went from {len(test_samples)} to {len(resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27291731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "    data_dir: Path,\n",
    "    balanced: bool = True,\n",
    "    batch_size: int = 32,\n",
    "    use_weighted_sampling: bool = False,\n",
    "    samples_per_class: int = 358,\n",
    "    seed: int = 42\n",
    ") ->Generator[Tuple[np.array, np.ndarray], None, None]:\n",
    "    \"\"\"\n",
    "    MAIN FUNCTION- What we should use for loading data\n",
    "\n",
    "    Loads and batches lunar crater images for training/validation.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to data folder\n",
    "        balanced: True for balanced subset (prototype), false for all data (Final training)\n",
    "        use_weighted_sampling: Apply weighted sampling for imbalance data (only works when balanced = false)\n",
    "        batch_size: Number of images per batch\n",
    "        samples_per_class: For balanced mode only\n",
    "        seed: Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        Generator yielding (images, labels) batches\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if balanced:\n",
    "        print(f\"Creating BALANCED dataset ({samples_per_class} per class)\")\n",
    "        samples = create_balanced_subset(data_dir, samples_per_class, seed)\n",
    "        print (f\"Total images: {len(samples)}\")\n",
    "\n",
    "        #Create loader for balanced data\n",
    "        loader = create_array_dataloader(samples, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "\n",
    "    else:\n",
    "        print(f\"Creating FULL dataset (all available data)\")\n",
    "        samples = []\n",
    "        class_names = [\"ejecta\", \"oldcrater\", \"none\"]\n",
    "\n",
    "        for class_idx, class_name in enumerate(class_names):\n",
    "            class_path = data_dir / class_name\n",
    "            all_files = list(class_path.glob(\"*.jpg\"))\n",
    "            samples.extend([(img_path, class_idx) for img_path in all_files])\n",
    "\n",
    "            print(f\"{class_name}: {len(all_files)} images\")\n",
    "\n",
    "        print(f\"Total images {len(samples)}\")\n",
    "\n",
    "        if use_weighted_sampling:\n",
    "            print(f\"Applying weighted sampling strategy\")\n",
    "            #Resample the entire dataset with weights\n",
    "            resampled_samples = create_weighted_sampler(samples, seed=seed)\n",
    "            loader = create_array_dataloader(resampled_samples, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "\n",
    "        else:\n",
    "            #Standard imbalanced loader\n",
    "            print(f\"Using imbalanced data without weighting\")\n",
    "            loader = create_array_dataloader(samples, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "\n",
    "    #Create a data loader\n",
    "    loader = create_array_dataloader(samples, batch_size=batch_size, shuffle= True, seed=seed)\n",
    "\n",
    "    return loader\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lunar-crater-age-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
